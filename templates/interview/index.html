<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview Room</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .video-container {
            margin-bottom: 20px;
            text-align: center;
        }
        #videoFeed {
            width: 100%;
            max-width: 640px;
            border-radius: 8px;
        }
        .controls {
            margin-bottom: 20px;
            text-align: center;
        }
        button {
            padding: 10px 20px;
            margin: 0 5px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
        }
        #startRecording {
            background-color: #4CAF50;
            color: white;
        }
        #stopRecording {
            background-color: #f44336;
            color: white;
            display: none;
        }
        #runTTS {
            background-color: #2196F3;
            color: white;
        }
        button:hover {
            opacity: 0.9;
        }
        #status {
            margin: 10px 0;
            padding: 10px;
            border-radius: 4px;
            text-align: center;
        }
        .recordings-list {
            margin-top: 20px;
        }
        .recording-item {
            padding: 10px;
            border: 1px solid #ddd;
            margin-bottom: 10px;
            border-radius: 4px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .recording-item a {
            color: #2196F3;
            text-decoration: none;
        }
        .recording-item a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI Interview Room</h1>
        
        <div class="video-container">
            <video id="videoFeed" autoplay playsinline></video>
        </div>
        
        <div class="controls">
            <button id="startRecording" onclick="startRecording()">Start Recording</button>
            <button id="stopRecording" onclick="stopRecording()" style="display: none;">Stop Recording</button>
            <button id="runTTS" onclick="runTTS()">Run TTS Script</button>
        </div>
        
        <div id="status"></div>
        
        <div class="recordings-list">
            <h2>Recordings</h2>
            <div id="recordingsList"></div>
        </div>
    </div>

    <script>
        let mediaRecorder = null;
        let audioChunks = [];
        let audioContext = null;
        let mediaStreamSource = null;
        let processor = null;
        let recordingBuffer = [];

        // Initialize video feed
        async function initVideo() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                const videoFeed = document.getElementById('videoFeed');
                videoFeed.srcObject = stream;
            } catch (err) {
                console.error('Error accessing media devices:', err);
            }
        }

        // Start recording
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100
                    }
                });
                
                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                mediaStreamSource = audioContext.createMediaStreamSource(stream);
                
                // Create processor node
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                processor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    recordingBuffer.push(new Float32Array(inputData));
                };
                
                // Connect nodes
                mediaStreamSource.connect(processor);
                processor.connect(audioContext.destination);
                
                document.getElementById('startRecording').style.display = 'none';
                document.getElementById('stopRecording').style.display = 'inline-block';
                console.log('Recording started');
            } catch (error) {
                console.error('Error starting recording:', error);
                alert('Failed to start recording: ' + error.message);
            }
        }

        // Stop recording
        async function stopRecording() {
            if (processor && mediaStreamSource) {
                // Disconnect nodes
                mediaStreamSource.disconnect();
                processor.disconnect();
                
                // Convert buffer to WAV
                const wavBlob = await convertToWav(recordingBuffer);
                
                // Reset buffer
                recordingBuffer = [];
                
                // Upload the recording
                const formData = new FormData();
                formData.append('audio', wavBlob, 'recording.wav');

                try {
                    const response = await fetch('/api/upload/', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.error || 'Failed to upload recording');
                    }

                    const data = await response.json();
                    if (data.success) {
                        console.log('Recording uploaded successfully');
                        fetchRecordings();
                    } else {
                        throw new Error(data.error || 'Failed to upload recording');
                    }
                } catch (error) {
                    console.error('Error saving recording:', error);
                    alert('Failed to save recording: ' + error.message);
                }
                
                document.getElementById('startRecording').style.display = 'inline-block';
                document.getElementById('stopRecording').style.display = 'none';
                console.log('Recording stopped');
            }
        }

        // Convert audio buffer to WAV
        function convertToWav(audioData) {
            const numChannels = 1;
            const sampleRate = 44100;
            const bitsPerSample = 16;
            
            // Concatenate all audio data
            const concatenated = new Float32Array(audioData.reduce((acc, val) => acc + val.length, 0));
            let offset = 0;
            for (const chunk of audioData) {
                concatenated.set(chunk, offset);
                offset += chunk.length;
            }
            
            // Convert to 16-bit PCM
            const pcmData = new Int16Array(concatenated.length);
            for (let i = 0; i < concatenated.length; i++) {
                pcmData[i] = Math.max(-1, Math.min(1, concatenated[i])) * 0x7FFF;
            }
            
            // Create WAV header
            const header = new ArrayBuffer(44);
            const view = new DataView(header);
            
            // RIFF header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + pcmData.length * 2, true);
            writeString(view, 8, 'WAVE');
            
            // Format chunk
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true);
            view.setUint16(32, numChannels * bitsPerSample / 8, true);
            view.setUint16(34, bitsPerSample, true);
            
            // Data chunk
            writeString(view, 36, 'data');
            view.setUint32(40, pcmData.length * 2, true);
            
            // Combine header and PCM data
            const blob = new Blob([header, pcmData.buffer], { type: 'audio/wav' });
            return blob;
        }

        // Helper function to write strings to DataView
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // Run TTS script
        async function runTTS() {
            try {
                const statusDiv = document.getElementById('status');
                statusDiv.textContent = 'Starting TTS script...';
                
                const response = await fetch('/runtts/', {
                    method: 'GET'
                });
                
                if (!response.ok) {
                    throw new Error('Failed to run TTS script');
                }
                
                const data = await response.json();
                statusDiv.textContent = data.message || 'TTS script completed successfully';
            } catch (error) {
                console.error('Error running TTS script:', error);
                document.getElementById('status').textContent = 'Error: ' + error.message;
            }
        }

        // Fetch recordings
        async function fetchRecordings() {
            try {
                const response = await fetch('/api/recordings/');
                const recordings = await response.json();
                
                const recordingsList = document.getElementById('recordingsList');
                recordingsList.innerHTML = recordings.map(recording => `
                    <div class="recording-item">
                        <span>${recording.timestamp}</span>
                        <a href="${recording.url}" download>Download</a>
                    </div>
                `).join('');
            } catch (error) {
                console.error('Error fetching recordings:', error);
            }
        }

        // Initialize
        initVideo();
        fetchRecordings();
    </script>
</body>
</html> 